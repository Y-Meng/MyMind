{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intro\n",
    "\n",
    "问题原型：Text -> Label（文本分类：X->Y）\n",
    "\n",
    "行业baseline：\n",
    "用BoW表示sentences，然后用LR或者SVM做回归。（Fan et al.2018）\n",
    "\n",
    "深度学习是机器学习的一个分支。\n",
    "\n",
    "库：\n",
    "keras.io(theano&tf都支持)\n",
    "gensim（自然语言方面）\n",
    "\n",
    "# auto-encoder\n",
    "\n",
    "解决问题：\n",
    "1.无标签\n",
    "2.标签量太大（降维）\n",
    "\n",
    "original input-> Encoder -> compressed representation -> Decoder -> Reconstructed input\n",
    "\n",
    "作用：\n",
    "数据降噪；数据降维。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras安装\n",
    "\n",
    "1.安装后端tensorflow\n",
    "```\n",
    "sudo pip3 install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello, tensorflow'\n"
     ]
    }
   ],
   "source": [
    "# 测试tensorflow安装\n",
    "import tensorflow as tf\n",
    "hello = tf.constant(\"hello, tensorflow\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.安装keras\n",
    "```\n",
    "sudo pip3 install keras\n",
    "```\n",
    "3.安装sklearn\n",
    "```\n",
    "pip3 install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inited\n"
     ]
    }
   ],
   "source": [
    "# 使用keras实现基于字符的auto-encoder\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class ASCIIAutoencoder():\n",
    "    \"\"\"\"基于字符的auto encoder\"\"\"\n",
    "    \n",
    "    def __init__(self, sen_len=512, encoding_dim=32, epoch=50, val_ratio=0.3):\n",
    "        \"\"\"\n",
    "        Init\n",
    "        \n",
    "        :param sen_len:把sentences pad成相同的长度\n",
    "        :param encoding_dim:压缩后的维度dim\n",
    "        :param epoch:要跑多少epoch\n",
    "        :param kmeanmodel:简单的KNN clustering模型\n",
    "        \"\"\"\n",
    "        self.sen_len = sen_len\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.autoencoder = None\n",
    "        self.encoder = None\n",
    "        self.kmeanmodel = KMeans(n_clusters=2)\n",
    "        self.epoch = epoch\n",
    "        print(\"inited\")\n",
    "        \n",
    "    def preprocess(self, x, length=256):\n",
    "        \"\"\"\n",
    "        将x截取为length长度并使用ascii表示\n",
    "        \"\"\"\n",
    "    \n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        模型构建\n",
    "        :param x: input text\n",
    "        \"\"\"\n",
    "        \n",
    "        # 把所有的traintext描述成同一个size，并把每一个字符都换成ascii码\n",
    "        x_train = self.preprocess(x, length=self.sen_len)\n",
    "        \n",
    "        # 然后给input预留好位置\n",
    "        input_text = Input(shape=(self.sen_len,))\n",
    "        \n",
    "        # encoded 每经过一层，都被刷新成小一点的“压缩后表达式”\n",
    "        encoded = Dense(1024, activation='tanh')(input_text)\n",
    "        encoded = Dense(512, activation='tanh')(encoded)\n",
    "        encoded = Dense(128, activation='tanh')(encoded)\n",
    "        encoded = Dense(self.encoding_dim, activation='tanh')(encoded)\n",
    "        \n",
    "        # decoded 把刚刚压缩完成的东西，反过来还原为input_text\n",
    "        decoded = Dense(128, activation='tanh')(encoded)\n",
    "        decoded = Dense(512, activation='tanh')(decoded)\n",
    "        decoded = Dense(1024, activation='tanh')(decoded)\n",
    "        decoded = Dense(self.sen_len, activation='sigmoid')(decoded)\n",
    "        \n",
    "        # 整个从大到小再到大的model，叫做autoencoder\n",
    "        self.autoencoder = Model(input=input_text, output=decoded)\n",
    "        \n",
    "        # 只从大到小叫做encoder\n",
    "        self.encoder = Model(input=input_text, output=encoded)\n",
    "        \n",
    "        # 只从小到大是decoder\n",
    "        encoded_input = Input(shape=(1024,))\n",
    "        # autoencoder的最后一层应该是decoder的第一层\n",
    "        decoder_layer = self.autoencoder.layers[-1]\n",
    "        # 从头到尾联起来就是decoder\n",
    "        decoder = Model(input=endoded_input, output=decoder_layer(encoded_input))\n",
    "        \n",
    "        # compile\n",
    "        self.autoencoder.compile(optimizer='adam', lose='mse')\n",
    "        \n",
    "        # run\n",
    "        self.autoencoder.fit(x_train, x_train, nb_epoch=self.epoch, batch_size=1000, shuffle=True)\n",
    "        \n",
    "        # 自己拿自己train一下KNN，一件简单的机遇距离的分类器\n",
    "        x_train = self.encoder.predict(x_train)\n",
    "        self.kmeanmodel.fit(x_train)\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        做预测\n",
    "        \"\"\"\n",
    "        # 把输入ascii化，并且长度相等\n",
    "        x_test = self.preprocess(x, length=self.sen_len)\n",
    "        # 然后用encoder把test集压缩\n",
    "        x_test = self.encoder.predict(x_test)\n",
    "        # KNN分类\n",
    "        preds = self.kmeanmodel.predict(x_test)\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    ac = ASCIIAutoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN4Text\n",
    "\n",
    "1.卷积神经网络：卷积神经网络（Convolutional Neural Network,CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。 它包括卷积层(convolutional layer)和池化层(pooling layer)。\n",
    "\n",
    "![卷积神经网络](http://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/heS6wRSHVMn7nLwdz2xxAfTru2GG9QaYqvsoOgfKMlRQaShOkLtyF6iaZzicXQz88dtb3BiaNCjmNzVFcHoNGiaYoA/0?wx_fmt=gif)\n",
    "\n",
    "2.把文字表示为类似图片的形式（word2vec)\n",
    "\n",
    "每个词都表示为一个向量，一句话就成为了一个二维的矩阵模式（类似于图片像素矩阵）。就可以变为CNN可以处理的数据格式。\n",
    "\n",
    "## CNN案例\n",
    "\n",
    "数据获取\n",
    "RedditNews\n",
    "\n",
    "预处理：\n",
    "1. 去除非字母\n",
    "2. 全小写\n",
    "3. 去除stop words\n",
    "4. lemma(归一化，词根还原)\n",
    "5. text 2 vec\n",
    "6. 模型处理\n",
    "\n",
    "\n",
    "# RNN\n",
    "\n",
    "普通神经网络：NN\n",
    "有时间序列的神经网络：RNN\n",
    "\n",
    "相比于普通神经网络：多了自我循环过程。\n",
    "\n",
    "RNN（Recurrent Neural Network）是一类用于处理序列数据的神经网络。首先我们要明确什么是序列数据，摘取百度百科词条：时间序列数据是指在不同时间点上收集到的数据，这类数据反映了某一事物、现象等随时间的变化状态或程度。这是时间序列数据的定义，当然这里也可以不是时间，比如文字序列，但总归序列数据有一个特点——后面的数据跟前面的数据有关系。\n",
    "\n",
    "![RNN基础模型](https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170306142253375-175971779.png)\n",
    "\n",
    "RNN可以带上记忆\n",
    "\n",
    "# LSTM\n",
    "\n",
    "LSTM（long short-term memory）。长短期记忆网络是RNN的一种变体，RNN由于梯度消失的原因只能有短期记忆，LSTM网络通过精妙的门控制将短期记忆与长期记忆结合起来，并且一定程度上解决了梯度消失的问题。 \n",
    "\n",
    "![lstm](https://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n",
    "\n",
    "LSTM最重要的就是cell state它一路向下，贯穿整个时间线，代表了记忆的纽带。使用XOR进行遗忘，AND进行记忆，使用Gate控制记忆或遗忘。\n",
    "\n",
    "第一步：忘记门，决定我们会从细胞状态中丢弃什么信息。\n",
    "![](https://upload-images.jianshu.io/upload_images/42741-96b387f711d1d12c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n",
    "\n",
    "第二步：记忆门，确定什么样的新信息被存放在细胞状态中。\n",
    "![](https://img-blog.csdn.net/20160731214331118)\n",
    "\n",
    "第三步：更新门，使用XOR和AND这样的门来更新cell state，sigmoid函数选择更新内容，tanh函数创建更新候选。\n",
    "![](https://img-blog.csdn.net/20160731215529417)\n",
    "\n",
    "第四步：输出门，确定输出什么值。\n",
    "![](https://img-blog.csdn.net/20160731220103283)\n",
    "\n",
    "案例：\n",
    "1. 维度，下一个单词，下一个句子，下一个...\n",
    "\n",
    "\n",
    "# 案例：用RNN做文本生成\n",
    "\n",
    "使用LSTM，丘吉尔人物传记作为学习语料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步：导入各种库，最好用好的GPU跑，普通笔记本跑完需要一个星期吧。。。\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 把文本读入\n",
    "raw_text = open('../data/Winston_Churchil.txt').read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# 用one_hot编码所有字母\n",
    "chars = sorted(list(set(row_text)))\n",
    "\n",
    "# 构造训练集\n",
    "\n",
    "# 改造为LSTM需要的数组格式【样本数，时间步伐，特征】；output变为one-hot编码\n",
    "\n",
    "# 构造模型\n",
    "\n",
    "# 跑模型\n",
    "\n",
    "# 预测"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
