{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯\n",
    "\n",
    "## 1.引言\n",
    "\n",
    "贝叶斯公式又被称为贝叶斯定理、贝叶斯规则是概率统计中的应用所观察到的现象对有关概率分布的主观判断（即先验概率）进行修正的标准方法。\n",
    "贝叶斯的统计学中有一个基本的工具叫贝叶斯公式、也称为贝叶斯法则， 尽管它是一个数学公式，但其原理毋需数字也可明了。如果你看到一个人总是做一些好事，则那个人多半会是一个好人。这就是说，当你不能准确知悉一个事物的本质时，你可以依靠与事物特定本质相关的事件出现的多少去判断其本质属性的概率。 用数学语言表达就是：支持某项属性的事件发生得愈多，则该属性成立的可能性就愈大。\n",
    "\n",
    "历史悠久，具有坚实的理论基础。\n",
    "\n",
    "## 2.贝叶斯公式\n",
    "\n",
    "贝叶斯\n",
    "> $ P(Y|X)=\\frac{P(X|Y)P(Y)}{P(X)} $\n",
    "\n",
    "它其实是由下面的联合概率公式推导出来的：\n",
    "> $ P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y) $\n",
    "\n",
    "其中P(Y)叫做先验概率，P(Y|X)叫做后验概率，P(Y,X)叫做联合概率。\n",
    "\n",
    "## 3.从机器学习的视角理解贝叶斯公式\n",
    "\n",
    "在机器学习中，我们把X理解为**具有某特征**，把Y理解成**类别标签**（一般机器学习中都是X=>特征，Y=>结果）。在简单的二分类问题中，我们将Y理解成**属于某类**的标签，于是上边的公式就变成了：\n",
    "\n",
    "> $ P(\"属于某类\"|\"具有某特征\")=\\frac{P(\"具有某特征\"|\"属于某一类\")P(\"属于某类\")}{P(\"具有某特征\")} $ \n",
    "\n",
    "二分类问题的最终目的就是要判断P(\"属于某类\"|\"具有某特征\")是否大于1/2就够了。\n",
    "贝叶斯方法把计算**“具有某特征条件下属于某类”**的概率转化为计算**“属于某类的条件下具有某特征”**的概率，而后者的获取方法就简单多了，我们只需要找到一些包含已知特征标签的样本，即可进行训练。而样本的类别标签都是明确的，所以贝叶斯方法在机器学习里属于有监督学习方法。\n",
    "\n",
    "## 4.以垃圾邮件识别理解贝叶斯二分类\n",
    "\n",
    "比如我们要对邮件进行分类，识别垃圾邮件和普通邮件，如果我们选择朴素贝叶斯分类器，那目标就是判断**P(\"垃圾邮件\"|\"我司可办理正规发票\")**的概率是否大于1/2。\n",
    "\n",
    "也就是出现“我司可办理正规发票”的邮件中是垃圾邮件的概率。\n",
    "\n",
    "\n",
    "## 5.分词\n",
    "\n",
    "实际情况中，我们对一句话的统计比较难表达实际含义，我们通过分词把一句话分为一组词语来表示：“我司”“可”“办理”“正规”“发票”\n",
    "\n",
    "## 6.条件独立假设\n",
    "\n",
    "引入**朴素近似**，方便计算\n",
    "\n",
    "## 7.朴素贝叶斯（naive bayes），朴素在何处\n",
    "\n",
    "加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法。\n",
    "\n",
    "朴素贝叶斯失去了词语之间的顺序信息！相当于把所有词汇都扔进一个袋子里搅和，贝叶斯都认为它们一样，也叫做“词袋模型（bag of words）”。\n",
    "\n",
    "所以这里：”武松打死老虎“和“老虎打死武松”是一样的意思了。\n",
    "\n",
    "## 8.朴素贝叶斯虽然简单，但是针对垃圾邮件等二分类效果极好\n",
    "\n",
    "只要样本量够大：简单、使用、强大。\n",
    "\n",
    "## 9.处理重复词的三种方式\n",
    "\n",
    "### 9.1.多项式模型\n",
    "\n",
    "出现多次，统计多次\n",
    "\n",
    "### 9.2.伯努利模型\n",
    "\n",
    "出现多次，认为一次\n",
    "\n",
    "### 9.3.混合模型\n",
    "\n",
    "计算句子概率，不考虑重复词语出现次数；计算词语概率时，考虑重复词语出现次数。\n",
    "\n",
    "## 10.去除停用词与选择关键词\n",
    "\n",
    "“停用词”和“关键词”一般都可以提前靠人工经验指定，不同的“停用词”和“关键词”训练出的分类器效果也会有差异。\n",
    "\n",
    "## 11.浅谈平滑技术\n",
    "\n",
    "解决某个词概率为0的问题。\n",
    "\n",
    "\n",
    "如果数据集够大，平滑技术对结果的影响将变小。\n",
    "\n",
    "## 12.实际工程tricks\n",
    "\n",
    "### 取对数（乘法 转 加法）\n",
    "\n",
    "### 转换为权重\n",
    "\n",
    "### topK关键词\n",
    "\n",
    "### 分割样本\n",
    "\n",
    "### 位置权重\n",
    "\n",
    "### 蜜罐\n",
    "\n",
    "\n",
    "## 13.贝叶斯方法的思维方式\n",
    "\n",
    "### 1.逆概问题\n",
    "\n",
    "### 2.处理多分类问题\n",
    "\n",
    "### 3.先验概率问题\n",
    "\n",
    "样本不平衡问题\n",
    "\n",
    "## 14.朴素贝叶斯方法常见应用\n",
    "\n",
    "### 1.褒贬分析\n",
    "\n",
    "### 2.拼写错误\n",
    "\n",
    "## 15.朴素贝叶斯应用练习\n",
    "\n",
    "### 贝叶斯分类器\n",
    "\n",
    "### 语种检测\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
